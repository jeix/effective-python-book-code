{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Concurrency and Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 62 Mix Threads and Coroutines to Ease the Transition to `asyncio`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> cannot run within Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoNewData(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readline(handle):\n",
    "    offset = handle.tell()\n",
    "    handle.seek(0, 2)\n",
    "    length = handle.tell()\n",
    "\n",
    "    if length == offset:\n",
    "        raise NoNewData\n",
    "\n",
    "    handle.seek(offset, 0)\n",
    "    return handle.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_file(handle, interval, write_func):\n",
    "    while not handle.closed:\n",
    "        try:\n",
    "            line = readline(handle)\n",
    "        except NoNewData:\n",
    "            time.sleep(interval)\n",
    "        else:\n",
    "            write_func(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_threads(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        lock = Lock()\n",
    "        def write(data):\n",
    "            with lock:\n",
    "                output.write(data)\n",
    "\n",
    "        threads = []\n",
    "        for handle in handles:\n",
    "            args = (handle, interval, write)\n",
    "            thread = Thread(target=tail_file, args=args)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all code to simulate the writers to the handles\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "def write_random_data(path, write_count, interval):\n",
    "    with open(path, 'wb') as f:\n",
    "        for i in range(write_count):\n",
    "            time.sleep(random.random() * interval)\n",
    "            letters = random.choices(\n",
    "                string.ascii_lowercase, k=10)\n",
    "            data = f'{path}-{i:02}-{\"\".join(letters)}\\n'\n",
    "            f.write(data.encode())\n",
    "            f.flush()\n",
    "\n",
    "def start_write_threads(directory, file_count):\n",
    "    paths = []\n",
    "    for i in range(file_count):\n",
    "        path = os.path.join(directory, str(i))\n",
    "        with open(path, 'w'):\n",
    "            # Make sure the file at this path will exist when\n",
    "            # the reading thread tries to poll it.\n",
    "            pass\n",
    "        paths.append(path)\n",
    "        args = (path, 10, 0.1)\n",
    "        thread = Thread(target=write_random_data, args=args)\n",
    "        thread.start()\n",
    "    return paths\n",
    "\n",
    "def close_all(handles):\n",
    "    time.sleep(1)\n",
    "    for handle in handles:\n",
    "        handle.close()\n",
    "\n",
    "def setup():\n",
    "    tmpdir = TemporaryDirectory()\n",
    "    input_paths = start_write_threads(tmpdir.name, 5)\n",
    "\n",
    "    handles = []\n",
    "    for path in input_paths:\n",
    "        handle = open(path, 'rb')\n",
    "        handles.append(handle)\n",
    "\n",
    "    Thread(target=close_all, args=(handles,)).start()\n",
    "\n",
    "    output_path = os.path.join(tmpdir.name, 'merged')\n",
    "    return tmpdir, input_paths, handles, output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_merge(input_paths, output_path):\n",
    "    found = collections.defaultdict(list)\n",
    "    with open(output_path, 'rb') as f:\n",
    "        for line in f:\n",
    "            for path in input_paths:\n",
    "                if line.find(path.encode()) == 0:\n",
    "                    found[path].append(line)\n",
    "\n",
    "    expected = collections.defaultdict(list)\n",
    "    for path in input_paths:\n",
    "        with open(path, 'rb') as f:\n",
    "            expected[path].extend(f.readlines())\n",
    "\n",
    "    for key, expected_lines in expected.items():\n",
    "        found_lines = found[key]\n",
    "        assert expected_lines == found_lines, \\\n",
    "            f'{expected_lines!r} == {found_lines!r}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "run_threads(handles, 0.1, output_path)\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Windows, a ProactorEventLoop can't be created within\n",
    "# threads because it tries to register signal handlers. This\n",
    "# is a work-around to always use the SelectorEventLoop policy\n",
    "# instead. See: https://bugs.python.org/issue33792\n",
    "policy = asyncio.get_event_loop_policy()\n",
    "policy._loop_factory = asyncio.SelectorEventLoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_tasks_mixed(handles, interval, output_path):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        def write(data):\n",
    "            coro = write_async(data)\n",
    "            future = asyncio.run_coroutine_threadsafe(\n",
    "                coro, loop)\n",
    "            future.result()\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            task = loop.run_in_executor(\n",
    "                None, tail_file, handle, interval, write)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "asyncio.run(run_tasks_mixed(handles, 0.1, output_path))\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def tail_async(handle, interval, write_func):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    while not handle.closed:\n",
    "        try:\n",
    "            line = await loop.run_in_executor(\n",
    "                None, readline, handle)\n",
    "        except NoNewData:\n",
    "            await asyncio.sleep(interval)\n",
    "        else:\n",
    "            await write_func(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_tasks(handles, interval, output_path):\n",
    "    with open(output_path, 'wb') as output:\n",
    "        async def write_async(data):\n",
    "            output.write(data)\n",
    "\n",
    "        tasks = []\n",
    "        for handle in handles:\n",
    "            coro = tail_async(handle, interval, write_async)\n",
    "            task = asyncio.create_task(coro)\n",
    "            tasks.append(task)\n",
    "\n",
    "        await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "asyncio.run(run_tasks(handles, 0.1, output_path))\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tail_file(handle, interval, write_func):\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "    async def write_async(data):\n",
    "        write_func(data)\n",
    "\n",
    "    coro = tail_async(handle, interval, write_async)\n",
    "    loop.run_until_complete(coro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir, input_paths, handles, output_path = setup()\n",
    "\n",
    "run_threads(handles, 0.1, output_path)\n",
    "\n",
    "confirm_merge(input_paths, output_path)\n",
    "\n",
    "tmpdir.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - `asyncio` 이벤트 루프의 `run_in_executor` 메서드(이 메서드에 대해 `await`를 사용해 완료를 기다릴 수 있다)를 사용하면 코루틴이 `ThreaPoolExecutor` 스레드 풀을 사용해 동기적인 함수를 호출할 수 있다. 이 기능을 활용하면 코드를 하향식으로 `asyncio`로 마이그레이션할 수 있다.\n",
    "> - `asyncio` 이벤트 루프의 `run_until_complete` 메서드를 사용하면 동기적인 코드가 코루틴을 호출하고 완료를 기다릴 수 있다. `asyncio.run_coroutine_threadsafe`도 같은 기능을 제공하지만 스레드 경계에서도 안전하게 작동한다. 이 두 메서드를 활용하면 코드를 상향식으로 `ayncio`로 마이그레이션할 때 도움이 된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
